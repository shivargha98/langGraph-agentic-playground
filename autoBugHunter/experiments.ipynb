{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c779f80-33a1-4967-a14b-84d307e1c6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "from pprint import pprint\n",
    "from typing import TypedDict, List, Annotated, Union, Dict, Any\n",
    "from langchain_core.messages import BaseMessage,AIMessage,HumanMessage,SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from langgraph.graph import StateGraph, END, add_messages\n",
    "import operator\n",
    "from langchain_core.tools import tool\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f6ec365-b9b7-4a11-a3b8-8e698e9760b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gemini = ChatGoogleGenerativeAI(model = 'gemini-2.0-flash',temperature=0,max_retries=2)\n",
    "llm_model_groq = ChatGroq(model = 'llama-3.1-8b-instant')\n",
    "llm_qwen_coder = ChatOllama(model=\"qwen2.5-coder:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a2e3439-036e-4101-ba9e-3557d84fda15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The error message \"Not able to print numeric 10\" indicates that there is an issue with the code execution. The Python interpreter attempts to convert the string \"10\" into a number, which is not possible because it is not a valid integer or float value. To resolve this issue, you need to ensure that the input is a valid number before attempting to print it. You can use the `isdigit()` method to check if the input contains only digits and then convert it to an integer using the `int()` function. Here\\'s an example of how you can modify the code:\\n```python\\ndef main():\\n    user_input = input(\"Enter a numeric value: \")\\n    if user_input.isdigit():\\n        print(int(user_input))\\n    else:\\n        print(\"Please enter a valid numeric value.\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n\\nIn this modified code, we first prompt the user to enter a numeric value using the `input()` function. We then check if the input contains only digits using the `isdigit()` method. If it does, we convert the input string to an integer using the `int()` function and print the result. If the input does not contain only digits, we print an error message asking the user to enter a valid numeric value.', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:1.5b', 'created_at': '2025-07-07T14:25:36.915966444Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15792208532, 'load_duration': 828088421, 'prompt_eval_count': 120, 'prompt_eval_duration': 71763003, 'eval_count': 261, 'eval_duration': 14844191261, 'message': Message(role='assistant', content='', thinking=None, images=None, tool_calls=None)}, id='run-52de013d-b7a5-47df-9f1c-0e52b53600bd-0', usage_metadata={'input_tokens': 120, 'output_tokens': 261, 'total_tokens': 381})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize Mistral LLM from Ollama\n",
    "\n",
    "llm_qwen_coder.invoke('''You are an expert Python code reviewer, you can understand the python code in a logical way\n",
    "    Here is the python code:\n",
    "    print(10\")\n",
    "\n",
    "    Here is the user reported issue:\n",
    "    {Not able to print numeric 10}\n",
    "\n",
    "    Base on the above issue, Think carefully: What could be causing this issue based on the logic, syntax, or control flow?\n",
    "    Respond with your reasoning in 2–3 sentences.\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e92a5ae-82a8-4195-8be7-f39607edc3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "\n",
    "    code_history: List[BaseMessage]\n",
    "    query_issue: List[BaseMessage] # General question history\n",
    "    think_history: Dict[str,List[BaseMessage]]# Thoughts by agents\n",
    "    act_history: Dict[str,List[BaseMessage]]# Actions taken\n",
    "    observe_history: Dict[str,List[BaseMessage]] # Observations received\n",
    "    reflect_history: Dict[str,List[BaseMessage]] # Reflexion checkpoints\n",
    "    message_history_after_vote = Annotated[List[BaseMessage],add_messages] ##message history after voting, (will encompass user query & code gen,doc gen part)\n",
    "    max_iterations: int\n",
    "    code_bug_detection: Dict[str,List[str]] # e.g., {\"qwen\": [\"off by one\"], \"gemini\": [\"loop never ends\"]}\n",
    "    line_localisation: Dict[str,List[int]] # e.g., {\"qwen\": [12, 14], \"gemini\": [13]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa74941e-1df0-43bd-8b5a-dfbb8ca7eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class thinkNodeOut(BaseModel):\n",
    "    output_response: str = Field(...,description='Paragraph with 2-3 sentences on why the code has a particular issue')\n",
    "    \n",
    "def thinkNode(state: AgentState):\n",
    "\n",
    "    llm_choices = {'gemini':llm_gemini,'groq':llm_model_groq,'qwen':llm_qwen_coder}\n",
    "    THINK_PROMPT = '''\n",
    "    You are an expert Python code reviewer, you can understand the python code in a logical way\n",
    "    Here is the python code:\n",
    "    {python_code}\n",
    "\n",
    "    Here is the user reported issue:\n",
    "    {query_issue}\n",
    "\n",
    "    Base on the above issue, Think carefully: What could be causing this issue based on the logic, syntax, or control flow?\n",
    "    Respond with your reasoning in a single paragraph with 2–3 sentences.\n",
    "    '''\n",
    "    think_prompt_template = ChatPromptTemplate.from_template(THINK_PROMPT)\n",
    "    #chain_list = {}\n",
    "    for llm_model in list(llm_choices.keys()):\n",
    "        print(llm_model)\n",
    "        think_chain = think_prompt_template | llm_choices[llm_model].with_structured_output(thinkNodeOut)\n",
    "        query_issue = state['query_issue'][-1].content\n",
    "        #print(query_issue)\n",
    "        code = state['code'][-1].content\n",
    "        print(code)\n",
    "        #print(query_issue,code)\n",
    "        thought_response = think_chain.invoke({'python_code':code,'query_issue':query_issue})\n",
    "        #print(thought_response)\n",
    "        state['think_history'][llm_model].append(AIMessage(content=thought_response.output_response))\n",
    "    \n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9c7f9fc9-15d6-4b51-8db0-60899b67562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini\n",
      "print(10\")\n",
      "groq\n",
      "print(10\")\n",
      "qwen\n",
      "print(10\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'think_history': {'gemini': [AIMessage(content='The code has a syntax error. The issue is likely due to a missing closing parenthesis which causes the interpreter to not understand the command. The correct syntax should be print(10).', additional_kwargs={}, response_metadata={})],\n",
       "  'groq': [AIMessage(content='The issue is likely due to a missing closing parenthesis in the print statement, which would result in a syntax error. This would cause the interpreter to fail, preventing the numeric value 10 from being printed. The corrected code would be print(10) with an added closing parenthesis.', additional_kwargs={}, response_metadata={})],\n",
       "  'qwen': [AIMessage(content='The user is trying to print the integer number 10, but instead, they receive an error message indicating that they cannot print numeric 10. This issue is likely due to incorrect syntax or missing quotes around the integer value in the `print()` function call.', additional_kwargs={}, response_metadata={})]},\n",
       " 'code': [HumanMessage(content='print(10\")', additional_kwargs={}, response_metadata={})],\n",
       " 'query_issue': [HumanMessage(content='Cannot print numeric 10', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_after_think = thinkNode({'think_history':{'gemini':[],'groq':[],'qwen':[]},'code':[HumanMessage(content='print(10\")')], \\\n",
    "           'query_issue':[HumanMessage(content='Cannot print numeric 10')]})\n",
    "state_after_think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff90d0-e31a-40e1-85bd-642020d89e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tools###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61d4cc-7f56-453d-ad51-2ae0cb272d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actNode(state:AgentState):\n",
    "    act_prompt = '''\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fef4a-91dd-4021-86d1-e9fef8e122b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d5298-a3f9-4b30-bbef-1272f601f26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b271e78-eb67-450e-ab4d-58966da7b592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5504b0-bd89-4e18-bfc9-c2ac749a6384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2dac26-7813-4258-b076-2df6122c7684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8441adcf-17cd-42ad-b5ab-2ab57ed73034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def buggy_code():\\n    print(\"Hello\")\\n    print(10)\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "import textwrap\n",
    "def buggy_code():\n",
    "    print(\"Hello\")\n",
    "    print(10)\n",
    "\n",
    "# Convert to string\n",
    "code_string = textwrap.dedent(inspect.getsource(buggy_code))\n",
    "code_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a7639-b7a2-40c3-bd84-7291c83f40e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b52e38-345d-46c5-871e-a96560335aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11baa43-21c1-497c-a876-4e9ceb251448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550aa342-3813-4342-9749-f2a1701146fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "464736c1-da35-4e0f-982a-9cef9f516739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  1: def example():\\n  2:     x = 5\\n  3:     print(\"x =\", x)'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "import textwrap\n",
    "from typing import Union, List\n",
    "\n",
    "def format_code_for_llm(\n",
    "    code: Union[str, List[str], object], \n",
    "    wrap_backticks: bool = False, \n",
    "    add_line_numbers: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Formats Python code into a string suitable for LLM input.\n",
    "    \n",
    "    Args:\n",
    "        code: Code as a string, list of lines, or a function/class object.\n",
    "        wrap_backticks: Whether to wrap output in triple backticks.\n",
    "        add_line_numbers: Whether to add line numbers for each line.\n",
    "        \n",
    "    Returns:\n",
    "        A formatted code string.\n",
    "    \"\"\"\n",
    "    if isinstance(code, list):\n",
    "        code_str = \"\\n\".join(code)\n",
    "    elif callable(code):\n",
    "        code_str = inspect.getsource(code)\n",
    "    elif isinstance(code, str):\n",
    "        code_str = code\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported input type. Use str, list, or function/class.\")\n",
    "\n",
    "    # Dedent and clean\n",
    "    code_str = textwrap.dedent(code_str).strip()\n",
    "    code_lines = code_str.split(\"\\n\")\n",
    "\n",
    "    if add_line_numbers:\n",
    "        code_lines = [f\"{i+1:3}: {line}\" for i, line in enumerate(code_lines)]\n",
    "        code_str = \"\\n\".join(code_lines)\n",
    "\n",
    "    if wrap_backticks:\n",
    "        return f\"```\\n{code_str}\\n```\"\n",
    "    return code_str\n",
    "def example():\n",
    "    x = 5\n",
    "    print(\"x =\", x)\n",
    "\n",
    "format_code_for_llm(example, add_line_numbers=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
